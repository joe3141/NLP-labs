{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, parsing and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 96 ms, sys: 20 ms, total: 116 ms\n",
      "Wall time: 115 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from nltk import pos_tag, sent_tokenize, word_tokenize, FreqDist\n",
    "from nltk.corpus import words\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import enchant\n",
    "import pyphen\n",
    "\n",
    "corpus = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(\"lingspam_public/bare/\"):\n",
    "    for file in files:\n",
    "    \twith open(os.path.join(root, file), \"r\") as f:\n",
    "    \t\tcorpus.append(f.read().strip())\n",
    "    \t\tif file[0] == 's': # Spam?\n",
    "    \t\t\tlabels.append(1)\n",
    "    \t\telse:\n",
    "    \t\t\tlabels.append(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(corpus, labels, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a bag-of-words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.72 s, sys: 428 ms, total: 2.15 s\n",
      "Wall time: 2.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# BOW\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "# Vectorize & append labels\n",
    "train = np.hstack((vectorizer.fit_transform(X_train).toarray(), np.array(y_train)[:, None]))\n",
    "test  = np.hstack((vectorizer.transform(X_test).toarray(), np.array(y_test)[:, None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper parameter tuning (e.g., using random search) would give better results as well as feature selection.\n",
    "def classify(train, test, train_offset=1):\n",
    "\n",
    "    X_train = train[:, :train.shape[1]-train_offset]\n",
    "    y_train = train[:, train.shape[1]-1]\n",
    "\n",
    "    X_test = test[:, :test.shape[1]-train_offset]\n",
    "    y_test = test[:, test.shape[1]-1]\n",
    "    \n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(X_train, y_train)\n",
    "\n",
    "    mnb_preds = mnb.predict(X_test)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    knn_preds = knn.predict(X_test)\n",
    "\n",
    "\n",
    "    rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    rf_preds = rf.predict(X_test)\n",
    "\n",
    "\n",
    "    print(\"Naive Bayes Report:\\n\")\n",
    "    print(classification_report(y_test, mnb_preds))\n",
    "\n",
    "    print(\"\\n\\nKNN Report:\\n\")\n",
    "    print(classification_report(y_test, knn_preds))\n",
    "\n",
    "    print(\"\\n\\nRandom Forest Report:\\n\")\n",
    "    print(classification_report(y_test, rf_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00       484\n",
      "          1       0.97      1.00      0.98        95\n",
      "\n",
      "avg / total       0.99      0.99      0.99       579\n",
      "\n",
      "\n",
      "\n",
      "KNN Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.87      0.92       484\n",
      "          1       0.57      0.92      0.70        95\n",
      "\n",
      "avg / total       0.91      0.87      0.88       579\n",
      "\n",
      "\n",
      "\n",
      "Random Forest Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       484\n",
      "          1       1.00      0.04      0.08        95\n",
      "\n",
      "avg / total       0.87      0.84      0.78       579\n",
      "\n",
      "CPU times: user 2min 19s, sys: 592 ms, total: 2min 19s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classify(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features from the documents\n",
    "### Reading spam word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_list = []\n",
    "with open(\"spam_word_list.txt\", \"r\") as f:\n",
    "\tspam_list = [word.strip().lower() for word in f.readlines() if word != \"\\n\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing dictionary and syllable counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = enchant.Dict(\"en_US\")\n",
    "pyphen.language_fallback('nl_NL_variant1')\n",
    "dic = pyphen.Pyphen(lang='en_GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to extract features (except for TF-IDF) from one document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(doc):\n",
    "\tdoc = doc.lower()\n",
    "\tres = []\n",
    "\ttokens = word_tokenize(doc)\n",
    "\tsents = sent_tokenize(doc)\n",
    "\t# Number of sentences\n",
    "\tres.append(len(sents))\n",
    "\n",
    "\t# Number of verbs\n",
    "\ttags = pos_tag(tokens)\n",
    "\tcounts = Counter(token[1] for token in tags)\n",
    "\tres.append(counts[\"VB\"])\n",
    "\n",
    "\t# Number of words that are found in the spam list\n",
    "\tspam_list_no = 0\n",
    "\tfor w in spam_list:\n",
    "\t\tif w in doc:\n",
    "\t\t\tspam_list_no += 1\n",
    "\n",
    "\tres.append(spam_list_no)\n",
    "\n",
    "\t# Number of spelling mistakes. Currently, not sensitive to other languages.\n",
    "\t# Number of words that contain both numeric and alphabetical chars,\n",
    "\ttypos = 0 \n",
    "\tnums = 0\n",
    "\t\n",
    "\t# Number of words with more than 3 syllables\n",
    "\tthree_syl_no = 0\n",
    "\t# Avg. number of syllables,\n",
    "\tavg_syl_word = 0\n",
    "\tword_no = 0\n",
    "\n",
    "\t# Sum of TF-ISF, Term frequence-Inverse sentence frequency\n",
    "\ttf_isf = 0.0\n",
    "\tf_terms = FreqDist(tokens)\n",
    "\n",
    "\tfor token in tokens:\n",
    "\t\t# Checks if this token is an English word\n",
    "\t\t# if token in words.words(): # It might be a proper word with no typos from a different language\n",
    "\t\tif not d.check(token):\n",
    "\t\t\ttypos +=1\n",
    "\n",
    "\t\tsyl_res = dic.inserted(token)\n",
    "\t\tsyls_no = len(syl_res.split(\"-\"))\n",
    "\n",
    "\t\tif syls_no > 3:\n",
    "\t\t\tthree_syl_no += 1\n",
    "\n",
    "\t\tword_no += 1\n",
    "\t\tavg_syl_word += syls_no\n",
    "\n",
    "\t\t# Not just numbers and contains at least one digit\n",
    "\t\tif not (token.isdigit()) and any(c.isdigit() for c in token):\n",
    "\t\t\tnums += 1\n",
    "\n",
    "\t\ttf = float(f_terms[token])\n",
    "\t\tisf = 0.0\n",
    "\t\tfor s in sents:\n",
    "\t\t\tif token in s:\n",
    "\t\t\t\tisf += 1.0\n",
    "\n",
    "\t\tif isf > 0.0:\n",
    "\t\t\tisf = (float(len(sents))) / isf\n",
    "\t\telse:\n",
    "\t\t\tisf = 0.0\n",
    "\t\ttf = 1.0 + np.log(tf)\n",
    "\t\ttf_isf += tf * isf\n",
    "\n",
    "\n",
    "\tavg_syl_word /= word_no\n",
    "\tres.extend((typos, nums, three_syl_no, avg_syl_word, tf_isf))\n",
    "\n",
    "\treturn res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vv = TfidfVectorizer(stop_words='english', sublinear_tf=True)\n",
    "train_tf_idf = np.sum(vv.fit_transform(X_train).toarray(), axis=1)\n",
    "test_tf_idf = np.sum(vv.transform(X_test).toarray(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the features from the entire corpus and building the dataset. (This takes ~ 245s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 24s, sys: 4.18 s, total: 3min 28s\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = np.hstack((np.array([extract_features(doc) for doc in X_train]), train_tf_idf[:, None], \\\n",
    "\tnp.array(y_train)[:, None]))\n",
    "\n",
    "test = np.hstack((np.array([extract_features(doc) for doc in X_test]), test_tf_idf[:, None], \\\n",
    "\tnp.array(y_test)[:, None]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for the new feature structure\n",
    "### Without TF-IDF & TF-ISF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.87      0.92       484\n",
      "        1.0       0.57      0.88      0.69        95\n",
      "\n",
      "avg / total       0.91      0.87      0.88       579\n",
      "\n",
      "\n",
      "\n",
      "KNN Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.98      0.96       484\n",
      "        1.0       0.88      0.73      0.80        95\n",
      "\n",
      "avg / total       0.94      0.94      0.94       579\n",
      "\n",
      "\n",
      "\n",
      "Random Forest Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.99      0.94       484\n",
      "        1.0       0.93      0.44      0.60        95\n",
      "\n",
      "avg / total       0.91      0.90      0.89       579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify(train, test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With TF-IDF & TF-ISF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.94      0.91       484\n",
      "        1.0       0.55      0.38      0.45        95\n",
      "\n",
      "avg / total       0.83      0.85      0.83       579\n",
      "\n",
      "\n",
      "\n",
      "KNN Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.94      0.90       484\n",
      "        1.0       0.46      0.27      0.34        95\n",
      "\n",
      "avg / total       0.80      0.83      0.81       579\n",
      "\n",
      "\n",
      "\n",
      "Random Forest Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.99      0.94       484\n",
      "        1.0       0.91      0.42      0.58        95\n",
      "\n",
      "avg / total       0.90      0.90      0.88       579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify(train, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
