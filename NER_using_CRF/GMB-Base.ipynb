{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "CPU times: user 60 ms, sys: 0 ns, total: 60 ms\n",
      "Wall time: 61.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pickle\n",
    "sents = pickle.load(open('conll2002-kaggle-2000.pickle', 'rb'))\n",
    "print(len(sents))\n",
    "\n",
    "split = int(0.8*len(sents))\n",
    "train_sents = sents[:split]\n",
    "test_sents = sents[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thousands', 'NNS', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('demonstrators', 'NNS', 'O'),\n",
       " ('have', 'VBP', 'O'),\n",
       " ('marched', 'VBN', 'O'),\n",
       " ('through', 'IN', 'O'),\n",
       " ('London', 'NNP', 'B-geo'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('protest', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('war', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('Iraq', 'NNP', 'B-geo'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('demand', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('withdrawal', 'NN', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('British', 'JJ', 'B-gpe'),\n",
       " ('troops', 'NNS', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('that', 'DT', 'O'),\n",
       " ('country', 'NN', 'O'),\n",
       " ('.', '.', 'O'),\n",
       " ('Thousands', 'NNS', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('demonstrators', 'NNS', 'O'),\n",
       " ('have', 'VBP', 'O'),\n",
       " ('marched', 'VBN', 'O'),\n",
       " ('through', 'IN', 'O'),\n",
       " ('London', 'NNP', 'B-geo'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('protest', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('war', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('Iraq', 'NNP', 'B-geo'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('demand', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('withdrawal', 'NN', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('British', 'JJ', 'B-gpe'),\n",
       " ('troops', 'NNS', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('that', 'DT', 'O'),\n",
       " ('country', 'NN', 'O'),\n",
       " ('.', '.', 'O'),\n",
       " ('Thousands', 'NNS', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('demonstrators', 'NNS', 'O'),\n",
       " ('have', 'VBP', 'O'),\n",
       " ('marched', 'VBN', 'O'),\n",
       " ('through', 'IN', 'O'),\n",
       " ('London', 'NNP', 'B-geo'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('protest', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('war', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('Iraq', 'NNP', 'B-geo'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('demand', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('withdrawal', 'NN', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('British', 'JJ', 'B-gpe'),\n",
       " ('troops', 'NNS', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('that', 'DT', 'O'),\n",
       " ('country', 'NN', 'O'),\n",
       " ('.', '.', 'O'),\n",
       " ('Thousands', 'NNS', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('demonstrators', 'NNS', 'O'),\n",
       " ('have', 'VBP', 'O'),\n",
       " ('marched', 'VBN', 'O'),\n",
       " ('through', 'IN', 'O'),\n",
       " ('London', 'NNP', 'B-geo'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('protest', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('war', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('Iraq', 'NNP', 'B-geo'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('demand', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('withdrawal', 'NN', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('British', 'JJ', 'B-gpe'),\n",
       " ('troops', 'NNS', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('that', 'DT', 'O'),\n",
       " ('country', 'NN', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "Next, define some features. In this example we use word identity, word suffix, word shape and word POS tag; also, some information from nearby words is used. \n",
    "\n",
    "This makes a simple baseline, but you certainly can add and remove some features to get (much?) better results - experiment with it.\n",
    "\n",
    "sklearn-crfsuite (and python-crfsuite) supports several feature formats; here we use feature dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def extract_more_features(word):\n",
    "    has_digits = False\n",
    "    has_uppers = False\n",
    "    \n",
    "    for c in word:\n",
    "        if c.isdigit():\n",
    "            has_digits = True\n",
    "        if c.isupper():\n",
    "            has_uppers = True\n",
    "            \n",
    "    return (has_digits, has_uppers)\n",
    "\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    t = extract_more_features(word)\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "        'hasDigits': t[0],\n",
    "        'hasUppers': t[1],\n",
    "        'firstTwoChars': word[:2],\n",
    "        'length': len(word),\n",
    "        'lemma': lemmatizer.lemmatize(word)\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    \n",
    "#     if i > 1:\n",
    "#         word2 = sent[i-2][0]\n",
    "#         postag2 = sent[i-2][1]\n",
    "#         features.update({\n",
    "#             '-2:word.lower()': word2.lower(),\n",
    "#             '-2:word.istitle()': word2.istitle(),\n",
    "#             '-2:word.isupper()': word2.isupper(),\n",
    "#             '-2:postag': postag2,\n",
    "#             '-2:postag[:2]': postag2[:2],\n",
    "#         })\n",
    "    \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "        \n",
    "#     if i < len(sent)-2:\n",
    "#         word2 = sent[i+2][0]\n",
    "#         postag2 = sent[i+2][1]\n",
    "#         features.update({\n",
    "#             '+2:word.lower()': word2.lower(),\n",
    "#             '+2:word.istitle()': word2.istitle(),\n",
    "#             '+2:word.isupper()': word2.isupper(),\n",
    "#             '+2:postag': postag2,\n",
    "#             '+2:postag[:2]': postag2[:2],\n",
    "#         })\n",
    "                \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what word2features extracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'+1:postag': 'VBP',\n",
       " '+1:postag[:2]': 'VB',\n",
       " '+1:word.istitle()': False,\n",
       " '+1:word.isupper()': False,\n",
       " '+1:word.lower()': 'have',\n",
       " '+2:postag': 'VBN',\n",
       " '+2:postag[:2]': 'VB',\n",
       " '+2:word.istitle()': False,\n",
       " '+2:word.isupper()': False,\n",
       " '+2:word.lower()': 'marched',\n",
       " '-1:postag': 'IN',\n",
       " '-1:postag[:2]': 'IN',\n",
       " '-1:word.istitle()': False,\n",
       " '-1:word.isupper()': False,\n",
       " '-1:word.lower()': 'of',\n",
       " '-2:postag': 'NNS',\n",
       " '-2:postag[:2]': 'NN',\n",
       " '-2:word.istitle()': True,\n",
       " '-2:word.isupper()': False,\n",
       " '-2:word.lower()': 'thousands',\n",
       " 'bias': 1.0,\n",
       " 'firstTwoChars': 'de',\n",
       " 'hasDigits': False,\n",
       " 'hasUppers': False,\n",
       " 'lemma': 'demonstrator',\n",
       " 'length': 13,\n",
       " 'postag': 'NNS',\n",
       " 'postag[:2]': 'NN',\n",
       " 'word.isdigit()': False,\n",
       " 'word.istitle()': False,\n",
       " 'word.isupper()': False,\n",
       " 'word.lower()': 'demonstrators',\n",
       " 'word[-2:]': 'rs',\n",
       " 'word[-3:]': 'ors'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train_sents[0])[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.62 s, sys: 24 ms, total: 2.64 s\n",
      "Wall time: 2.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "To see all possible CRF parameters check its docstring. Here we are useing L-BFGS training algorithm (it is default) with Elastic Net (L1 + L2) regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params = {'c1': scipy.stats.expon(scale=0.5), 'c2': scipy.stats.expon(scale=0.05)}\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=50, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "# crf.fit(X_train, y_train)\n",
    "\n",
    "gs = RandomizedSearchCV(crf, param_distributions=params)\n",
    "gs_res = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "There is much more O entities in data set, but we're more interested in other entities. To account for this we'll use averaged F1 score computed for all labels except for O. ``sklearn-crfsuite.metrics`` package provides some useful metrics for sequence classification task, including this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-geo',\n",
       " 'B-gpe',\n",
       " 'B-per',\n",
       " 'I-geo',\n",
       " 'B-org',\n",
       " 'I-org',\n",
       " 'B-tim',\n",
       " 'B-art',\n",
       " 'I-art',\n",
       " 'I-per',\n",
       " 'I-gpe',\n",
       " 'I-tim',\n",
       " 'B-nat',\n",
       " 'B-eve',\n",
       " 'I-eve',\n",
       " 'I-nat']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "# labels\n",
    "print(gs_res.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74558996471971772"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, average='micro', labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect per-class results in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-art      0.000     0.000     0.000         0\n",
      "      I-art      0.000     0.000     0.000         0\n",
      "      B-eve      0.400     0.182     0.250        44\n",
      "      I-eve      0.000     0.000     0.000        28\n",
      "      B-geo      0.740     0.770     0.755       996\n",
      "      I-geo      0.667     0.667     0.667       168\n",
      "      B-gpe      0.775     0.824     0.799       592\n",
      "      I-gpe      0.200     0.500     0.286         8\n",
      "      B-nat      0.000     0.000     0.000         8\n",
      "      I-nat      0.000     0.000     0.000         0\n",
      "      B-org      0.565     0.581     0.573       616\n",
      "      I-org      0.743     0.739     0.741       476\n",
      "      B-per      0.794     0.706     0.748       596\n",
      "      I-per      0.845     0.910     0.876       720\n",
      "      B-tim      0.931     0.771     0.844       704\n",
      "      I-tim      0.881     0.381     0.532       252\n",
      "\n",
      "avg / total      0.766     0.730     0.741      5208\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joe3141/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/joe3141/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "B-eve  -> I-eve   3.690174\n",
      "I-eve  -> I-eve   3.440612\n",
      "I-art  -> I-art   3.436977\n",
      "B-per  -> I-per   3.414614\n",
      "I-org  -> I-org   3.324302\n",
      "B-nat  -> I-nat   3.278195\n",
      "B-org  -> I-org   3.205937\n",
      "B-geo  -> I-geo   3.064063\n",
      "B-art  -> I-art   3.045358\n",
      "I-per  -> I-per   2.669580\n",
      "B-tim  -> I-tim   2.570981\n",
      "I-tim  -> I-tim   2.475548\n",
      "B-gpe  -> I-gpe   2.446508\n",
      "O      -> O       2.403821\n",
      "I-geo  -> I-geo   2.189821\n",
      "I-nat  -> I-nat   2.114438\n",
      "I-gpe  -> I-gpe   1.796349\n",
      "B-org  -> B-art   1.496428\n",
      "O      -> B-tim   0.745189\n",
      "B-gpe  -> B-org   0.706160\n",
      "\n",
      "Top unlikely transitions:\n",
      "B-geo  -> B-org   -2.972659\n",
      "B-geo  -> I-gpe   -3.028510\n",
      "B-org  -> I-geo   -3.049104\n",
      "O      -> I-nat   -3.086647\n",
      "B-tim  -> B-tim   -3.099261\n",
      "O      -> I-eve   -3.110203\n",
      "O      -> I-art   -3.141735\n",
      "I-org  -> I-per   -3.224418\n",
      "I-per  -> B-per   -3.309276\n",
      "B-org  -> I-per   -3.429796\n",
      "B-geo  -> I-per   -3.482263\n",
      "B-per  -> B-per   -3.525805\n",
      "B-geo  -> I-org   -3.563352\n",
      "O      -> I-gpe   -3.789578\n",
      "B-gpe  -> B-gpe   -3.830366\n",
      "B-gpe  -> I-org   -4.131179\n",
      "O      -> I-geo   -4.175536\n",
      "O      -> I-per   -5.077803\n",
      "O      -> I-org   -5.386455\n",
      "O      -> I-tim   -6.093652\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, for example, it is very likely that the beginning of an organization name (B-ORG) will be followed by a token inside organization name (I-ORG), but transitions to I-ORG from tokens with other labels are penalized.\n",
    "\n",
    "Check the state features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "4.566423 B-org    -2:word.lower():interest\n",
      "4.374259 B-gpe    -2:word.lower():concern\n",
      "4.216193 B-org    -2:word.lower():saturday\n",
      "3.889579 B-org    +2:word.lower():wrested\n",
      "3.880429 B-gpe    -2:word.lower():currently\n",
      "3.871938 B-gpe    +2:word.lower():build\n",
      "3.725769 O        postag[:2]:VB\n",
      "3.620111 B-gpe    firstTwoChars:Sw\n",
      "3.549836 B-tim    word[-3:]:ber\n",
      "3.523390 B-org    -1:word.lower():observed\n",
      "3.419723 B-tim    +1:word.lower():year\n",
      "3.407830 I-org    +2:word.lower():khartoum\n",
      "3.358308 O        word.lower():this\n",
      "3.335910 B-org    -2:word.lower():tariffs\n",
      "3.332753 B-org    +1:word.lower():democratic\n",
      "3.318072 B-gpe    +2:word.lower():scheduled\n",
      "3.300045 B-org    -2:word.lower():cultivation\n",
      "3.295296 O        word[-3:]:ice\n",
      "3.286607 B-geo    -2:word.lower():al-qaida\n",
      "3.252897 B-tim    word[-2:]:ay\n",
      "3.214567 B-tim    -1:word.lower():next\n",
      "3.211005 B-per    -2:word.lower():tamils\n",
      "3.208769 B-gpe    -1:word.lower():prompt\n",
      "3.194266 B-tim    word[-3:]:day\n",
      "3.188693 B-org    +2:word.lower():pay\n",
      "3.185639 B-gpe    +2:word.lower():military-led\n",
      "3.168427 B-gpe    +2:word.lower():kidnapping\n",
      "3.166952 B-org    -2:word.lower():canada\n",
      "3.117120 B-org    -2:word.lower():patients\n",
      "3.098918 B-org    +2:word.lower():operate\n",
      "\n",
      "Top negative:\n",
      "-1.661334 O        -1:word.lower():extremist\n",
      "-1.676947 O        postag:NNPS\n",
      "-1.696373 O        -1:word.lower():since\n",
      "-1.699510 B-gpe    -2:word.lower():on\n",
      "-1.714798 B-geo    -2:word.lower():conflict\n",
      "-1.735213 O        -1:word.lower():parliamentary\n",
      "-1.787014 B-gpe    firstTwoChars:Ba\n",
      "-1.828014 O        +1:word.lower():diplomat\n",
      "-1.831284 O        word[-2:]:03\n",
      "-1.857080 B-gpe    -2:word.lower():iraq\n",
      "-1.904840 O        -1:word.lower():rio\n",
      "-1.938873 O        firstTwoChars:Am\n",
      "-1.943651 O        +2:word.lower():eucharist\n",
      "-1.982043 I-per    +2:word.lower():in\n",
      "-2.025066 O        -1:word.lower():next\n",
      "-2.035558 O        word[-2:]:ca\n",
      "-2.066432 O        -1:word.lower():year\n",
      "-2.067482 O        +2:word.lower():month\n",
      "-2.109122 B-gpe    -2:word.lower():week\n",
      "-2.119922 B-geo    word[-2:]:ry\n",
      "-2.318394 O        firstTwoChars:20\n",
      "-2.344692 O        +2:word.lower():khartoum\n",
      "-2.454750 O        +2:word.lower():week\n",
      "-2.482975 O        firstTwoChars:Af\n",
      "-2.666083 O        +1:word.lower():attacked\n",
      "-2.752959 O        firstTwoChars:Pa\n",
      "-3.022868 B-org    firstTwoChars:No\n",
      "-3.367156 B-gpe    +2:word.isupper()\n",
      "-4.194133 O        postag:NNP\n",
      "-4.385425 O        firstTwoChars:19\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))    \n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(30))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
